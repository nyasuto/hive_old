"""
Hive Comb Markdown Logger - Markdownå½¢å¼ã§ã®é€šä¿¡ãƒ­ã‚°æ©Ÿèƒ½

Workeré–“ã®é€šä¿¡ã‚’äººé–“ã¨AIã«ã¨ã£ã¦èª­ã¿ã‚„ã™ã„Markdownå½¢å¼ã§è¨˜éŒ²
"""

from datetime import datetime, timedelta
from pathlib import Path
from typing import TYPE_CHECKING, Any

from .file_handler import HiveFileHandler

if TYPE_CHECKING:
    from .message_router import Message


class MarkdownLogger:
    """Markdownå½¢å¼ã§ã®é€šä¿¡ãƒ­ã‚°ç®¡ç†"""

    def __init__(self, file_handler: HiveFileHandler | None = None) -> None:
        """
        åˆæœŸåŒ–

        Args:
            file_handler: ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        """
        self.file_handler = file_handler or HiveFileHandler()
        self.file_handler.ensure_hive_structure()

        # é€šä¿¡ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.comm_logs_dir = self.file_handler.get_path("comb", "communication_logs")
        self.comm_logs_dir.mkdir(exist_ok=True)

        # æ—¥æ¬¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        today = datetime.now().strftime("%Y-%m-%d")
        self.daily_dir = self.comm_logs_dir / today
        self.daily_dir.mkdir(exist_ok=True)

    def log_message(self, message: "Message") -> bool:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Markdownå½¢å¼ã§ãƒ­ã‚°è¨˜éŒ²

        Args:
            message: è¨˜éŒ²ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            è¨˜éŒ²æˆåŠŸæ™‚True
        """
        try:
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            log_filename = f"{message.from_worker}_{message.to_worker}.md"
            log_file = self.daily_dir / log_filename

            # Markdownã‚¨ãƒ³ãƒˆãƒªç”Ÿæˆ
            markdown_entry = self._generate_markdown_entry(message)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
            return self._append_to_log_file(log_file, markdown_entry)

        except Exception as e:
            print(f"Error logging message to Markdown: {e}")
            return False

    def _generate_markdown_entry(self, message: "Message") -> str:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰Markdownã‚¨ãƒ³ãƒˆãƒªã‚’ç”Ÿæˆ

        Args:
            message: å¤‰æ›ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            Markdownã‚¨ãƒ³ãƒˆãƒªæ–‡å­—åˆ—
        """
        timestamp = datetime.fromisoformat(message.timestamp)
        formatted_time = timestamp.strftime("%H:%M:%S")

        # å„ªå…ˆåº¦ã®çµµæ–‡å­—ãƒãƒƒãƒ”ãƒ³ã‚°
        priority_emoji = {"LOW": "ğŸŸ¢", "NORMAL": "ğŸ”µ", "HIGH": "ğŸŸ ", "URGENT": "ğŸ”´"}

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã®çµµæ–‡å­—ãƒãƒƒãƒ”ãƒ³ã‚°
        type_emoji = {
            "request": "â“",
            "response": "âœ…",
            "notification": "ğŸ“¢",
            "error": "âŒ",
        }

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ•´å½¢
        content_md = self._format_content(message.content)

        markdown_entry = f"""
## {type_emoji.get(message.message_type.value, "ğŸ“")} {message.message_type.value.title()}

### {message.from_worker} â†’ {message.to_worker}
**Time:** {formatted_time}
**Priority:** {priority_emoji.get(message.priority.name, "âšª")} {message.priority.name}
**Message ID:** `{message.id}`

{content_md}

---

"""
        return markdown_entry

    def _format_content(self, content: dict[str, Any]) -> str:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’Markdownå½¢å¼ã«æ•´å½¢

        Args:
            content: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            æ•´å½¢ã•ã‚ŒãŸMarkdownæ–‡å­—åˆ—
        """
        if not content:
            return "*(Empty message)*"

        # ç‰¹æ®Šãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã®å‡¦ç†
        if "action" in content:
            action = content["action"]
            if action == "ping":
                return "ğŸ“ **Ping** - Health check request"
            elif action == "pong":
                return "ğŸ“ **Pong** - Health check response"

        # é€šå¸¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†
        formatted_lines = []
        for key, value in content.items():
            if isinstance(value, dict):
                formatted_lines.append(f"**{key.title()}:**")
                for sub_key, sub_value in value.items():
                    formatted_lines.append(f"  - {sub_key}: `{sub_value}`")
            elif isinstance(value, list):
                formatted_lines.append(f"**{key.title()}:**")
                for item in value:
                    formatted_lines.append(f"  - {item}")
            else:
                formatted_lines.append(f"**{key.title()}:** {value}")

        return "\n".join(formatted_lines)

    def _append_to_log_file(self, log_file: Path, content: str) -> bool:
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½è¨˜

        Args:
            log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content: è¿½è¨˜ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            æˆåŠŸæ™‚True
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
            if not log_file.exists():
                today = datetime.now().strftime("%Y-%m-%d")
                header = f"""# ğŸ Hive Communication Log - {today}

Workeré–“é€šä¿¡ã®è¨˜éŒ²

"""
                with open(log_file, "w", encoding="utf-8") as f:
                    f.write(header)

            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½è¨˜
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(content)

            return True

        except Exception as e:
            print(f"Error appending to log file {log_file}: {e}")
            return False

    def generate_daily_summary(self) -> bool:
        """
        æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ

        Returns:
            ç”ŸæˆæˆåŠŸæ™‚True
        """
        try:
            today = datetime.now().strftime("%Y-%m-%d")
            summary_file = self.daily_dir / f"summary_{today}.md"

            # å½“æ—¥ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            log_files = list(self.daily_dir.glob("*.md"))
            log_files = [f for f in log_files if not f.name.startswith("summary_")]

            if not log_files:
                return True  # ãƒ­ã‚°ãŒãªã„å ´åˆã¯æ­£å¸¸çµ‚äº†

            # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            summary_content = self._generate_summary_content(log_files)

            # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            with open(summary_file, "w", encoding="utf-8") as f:
                f.write(summary_content)

            return True

        except Exception as e:
            print(f"Error generating daily summary: {e}")
            return False

    def _generate_summary_content(self, log_files: list[Path]) -> str:
        """
        ã‚µãƒãƒªãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ

        Args:
            log_files: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ

        Returns:
            ã‚µãƒãƒªãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        today = datetime.now().strftime("%Y-%m-%d")
        summary_lines = [
            f"# ğŸ“Š Daily Communication Summary - {today}",
            "",
            "## ğŸ“ˆ Overview",
            f"**Total Communication Files:** {len(log_files)}",
            "",
            "## ğŸ“ Communication Files",
            "",
        ]

        for log_file in sorted(log_files):
            file_size = log_file.stat().st_size
            file_size_kb = file_size / 1024
            worker_pair = log_file.stem.replace("_", " â†” ")
            summary_lines.append(f"- **{worker_pair}** (`{file_size_kb:.1f}KB`)")

        summary_lines.extend(["", "## ğŸ” Quick Access", ""])

        for log_file in sorted(log_files):
            relative_path = log_file.name
            worker_pair = log_file.stem.replace("_", " â†” ")
            summary_lines.append(f"- [{worker_pair}](./{relative_path})")

        summary_lines.extend(
            ["", f"*Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"]
        )

        return "\n".join(summary_lines)

    def cleanup_old_logs(self, days_to_keep: int = 7) -> int:
        """
        å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

        Args:
            days_to_keep: ä¿æŒæ—¥æ•°

        Returns:
            å‰Šé™¤ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            deleted_count = 0

            for date_dir in self.comm_logs_dir.iterdir():
                if not date_dir.is_dir():
                    continue

                try:
                    dir_date = datetime.strptime(date_dir.name, "%Y-%m-%d")
                    if dir_date < cutoff_date:
                        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        for file in date_dir.glob("*"):
                            file.unlink()
                            deleted_count += 1
                        # ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
                        date_dir.rmdir()
                except ValueError:
                    # æ—¥ä»˜å½¢å¼ã§ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ç„¡è¦–
                    continue

            return deleted_count

        except Exception as e:
            print(f"Error cleaning up old logs: {e}")
            return 0

    def get_communication_stats(self) -> dict[str, Any]:
        """
        é€šä¿¡çµ±è¨ˆã‚’å–å¾—

        Returns:
            é€šä¿¡çµ±è¨ˆæƒ…å ±
        """
        try:
            stats = {
                "total_log_files": 0,
                "total_size_kb": 0,
                "worker_pairs": [],
                "daily_directories": 0,
            }

            # æ—¥æ¬¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°
            date_dirs = [d for d in self.comm_logs_dir.iterdir() if d.is_dir()]
            stats["daily_directories"] = len(date_dirs)

            # å½“æ—¥ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
            log_files = list(self.daily_dir.glob("*.md"))
            log_files = [f for f in log_files if not f.name.startswith("summary_")]

            stats["total_log_files"] = len(log_files)

            total_size = 0
            worker_pairs = set()

            for log_file in log_files:
                file_size = log_file.stat().st_size
                total_size += file_size
                worker_pairs.add(log_file.stem)

            stats["total_size_kb"] = total_size / 1024
            stats["worker_pairs"] = sorted(worker_pairs)

            return stats

        except Exception as e:
            print(f"Error getting communication stats: {e}")
            return {}
