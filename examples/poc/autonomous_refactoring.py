"""
è‡ªå¾‹çš„ã‚³ãƒ¼ãƒ‰ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’è‡ªå¾‹çš„ã«åˆ†æã—ã€å“è³ªæ”¹å–„ã‚’ç¶™ç¶šçš„ã«å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Šã€å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ ã€docstringç”Ÿæˆã€
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚

Usage:
    python examples/poc/autonomous_refactoring.py
"""

import ast
import asyncio
import json
import subprocess
import sys
from pathlib import Path
from typing import Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from examples.templates.autonomous_agent_template import AutonomousAgent


class CodeQualityAnalyzer:
    """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æå™¨"""

    def __init__(self):
        self.project_root = Path.cwd()
        self.python_files = []
        self._scan_python_files()

    def _scan_python_files(self) -> None:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        self.python_files = list(self.project_root.rglob("*.py"))
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚„éš ã—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é™¤å¤–
        self.python_files = [
            f
            for f in self.python_files
            if not any(part.startswith(".") for part in f.parts)
            and "test" not in f.name.lower()
            and "__pycache__" not in str(f)
        ]

    async def analyze_codebase(self) -> dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®åˆ†æ"""
        analysis = {
            "total_files": len(self.python_files),
            "quality_issues": [],
            "coverage_info": await self._get_test_coverage(),
            "type_annotation_coverage": await self._analyze_type_annotations(),
            "docstring_coverage": await self._analyze_docstring_coverage(),
            "complexity_analysis": await self._analyze_complexity(),
            "overall_score": 0,
        }

        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        for file_path in self.python_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
            file_analysis = await self._analyze_file(file_path)
            analysis["quality_issues"].extend(file_analysis)

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        analysis["overall_score"] = self._calculate_overall_score(analysis)

        return analysis

    async def _get_test_coverage(self) -> dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å–å¾—"""
        try:
            # pytestã§ã‚«ãƒãƒ¬ãƒƒã‚¸å®Ÿè¡Œ
            result = subprocess.run(
                ["python", "-m", "pytest", "--cov=.", "--cov-report=json", "--quiet"],
                capture_output=True,
                text=True,
                timeout=60,
            )

            if result.returncode == 0:
                coverage_file = Path("coverage.json")
                if coverage_file.exists():
                    with open(coverage_file) as f:
                        coverage_data = json.load(f)
                    coverage_file.unlink()  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

                    return {
                        "total_coverage": coverage_data.get("totals", {}).get(
                            "percent_covered", 0
                        ),
                        "lines_covered": coverage_data.get("totals", {}).get(
                            "covered_lines", 0
                        ),
                        "lines_total": coverage_data.get("totals", {}).get(
                            "num_statements", 0
                        ),
                    }

            return {"total_coverage": 0, "error": "Coverage analysis failed"}

        except Exception as e:
            return {"total_coverage": 0, "error": str(e)}

    async def _analyze_type_annotations(self) -> dict[str, Any]:
        """å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ"""
        total_functions = 0
        annotated_functions = 0

        for file_path in self.python_files:
            try:
                with open(file_path, encoding="utf-8") as f:
                    tree = ast.parse(f.read())

                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        total_functions += 1

                        # æˆ»ã‚Šå€¤ã®å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
                        has_return_annotation = node.returns is not None

                        # å¼•æ•°ã®å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
                        has_arg_annotations = any(
                            arg.annotation is not None for arg in node.args.args
                        )

                        if has_return_annotation or has_arg_annotations:
                            annotated_functions += 1

            except Exception:
                continue

        coverage = (annotated_functions / max(total_functions, 1)) * 100

        return {
            "type_annotation_coverage": coverage,
            "total_functions": total_functions,
            "annotated_functions": annotated_functions,
        }

    async def _analyze_docstring_coverage(self) -> dict[str, Any]:
        """docstringåˆ†æ"""
        total_functions = 0
        documented_functions = 0

        for file_path in self.python_files:
            try:
                with open(file_path, encoding="utf-8") as f:
                    tree = ast.parse(f.read())

                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef | ast.ClassDef):
                        total_functions += 1

                        # docstringã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                        if (
                            node.body
                            and isinstance(node.body[0], ast.Expr)
                            and isinstance(node.body[0].value, ast.Constant)
                        ):
                            documented_functions += 1

            except Exception:
                continue

        coverage = (documented_functions / max(total_functions, 1)) * 100

        return {
            "docstring_coverage": coverage,
            "total_functions": total_functions,
            "documented_functions": documented_functions,
        }

    async def _analyze_complexity(self) -> dict[str, Any]:
        """è¤‡é›‘åº¦åˆ†æ"""
        try:
            # raderã‚’ä½¿ç”¨ã—ã¦ã‚µã‚¤ã‚¯ãƒ­ãƒãƒ†ã‚£ãƒƒã‚¯è¤‡é›‘åº¦ã‚’åˆ†æ
            result = subprocess.run(
                ["python", "-m", "radon", "cc", ".", "--json"],
                capture_output=True,
                text=True,
                timeout=30,
            )

            if result.returncode == 0:
                complexity_data = json.loads(result.stdout)

                total_complexity = 0
                function_count = 0

                for file_data in complexity_data.values():
                    for item in file_data:
                        if item.get("type") == "function":
                            total_complexity += item.get("complexity", 0)
                            function_count += 1

                avg_complexity = total_complexity / max(function_count, 1)

                return {
                    "average_complexity": avg_complexity,
                    "total_functions": function_count,
                    "high_complexity_count": sum(
                        1
                        for file_data in complexity_data.values()
                        for item in file_data
                        if item.get("complexity", 0) > 10
                    ),
                }

            return {"average_complexity": 0, "error": "Complexity analysis failed"}

        except Exception as e:
            return {"average_complexity": 0, "error": str(e)}

    async def _analyze_file(self, file_path: Path) -> list[dict[str, Any]]:
        """å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ"""
        issues = []

        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
                tree = ast.parse(content)

            # é–¢æ•°åˆ†æ
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¶³
                    if node.returns is None:
                        issues.append(
                            {
                                "file": str(file_path),
                                "line": node.lineno,
                                "type": "missing_return_annotation",
                                "function": node.name,
                                "severity": "medium",
                            }
                        )

                    # docstringä¸è¶³
                    has_docstring = (
                        node.body
                        and isinstance(node.body[0], ast.Expr)
                        and isinstance(node.body[0].value, ast.Constant)
                    )

                    if not has_docstring:
                        issues.append(
                            {
                                "file": str(file_path),
                                "line": node.lineno,
                                "type": "missing_docstring",
                                "function": node.name,
                                "severity": "low",
                            }
                        )

        except Exception as e:
            issues.append(
                {
                    "file": str(file_path),
                    "type": "parse_error",
                    "error": str(e),
                    "severity": "high",
                }
            )

        return issues

    def _calculate_overall_score(self, analysis: dict[str, Any]) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—"""
        coverage_score = analysis["coverage_info"].get("total_coverage", 0)
        type_score = analysis["type_annotation_coverage"].get(
            "type_annotation_coverage", 0
        )
        doc_score = analysis["docstring_coverage"].get("docstring_coverage", 0)

        # é‡ã¿ä»˜ãå¹³å‡
        overall_score = (
            coverage_score * 0.4  # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸é‡è¦–
            + type_score * 0.3  # å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            + doc_score * 0.3  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        )

        return round(overall_score, 2)


class CodeRefactoringEngine:
    """ã‚³ãƒ¼ãƒ‰ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.project_root = Path.cwd()

    async def generate_improvements(
        self, analysis: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        improvements = []

        # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„
        coverage = analysis["coverage_info"].get("total_coverage", 0)
        if coverage < 80:
            improvements.append(
                {
                    "type": "test_coverage_improvement",
                    "current_coverage": coverage,
                    "target_coverage": 85,
                    "priority": "high",
                    "estimated_effort": "medium",
                }
            )

        # å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 
        type_coverage = analysis["type_annotation_coverage"].get(
            "type_annotation_coverage", 0
        )
        if type_coverage < 80:
            improvements.append(
                {
                    "type": "type_annotation_addition",
                    "current_coverage": type_coverage,
                    "target_coverage": 90,
                    "priority": "medium",
                    "estimated_effort": "low",
                }
            )

        # docstringè¿½åŠ 
        doc_coverage = analysis["docstring_coverage"].get("docstring_coverage", 0)
        if doc_coverage < 70:
            improvements.append(
                {
                    "type": "docstring_addition",
                    "current_coverage": doc_coverage,
                    "target_coverage": 85,
                    "priority": "low",
                    "estimated_effort": "medium",
                }
            )

        # è¤‡é›‘åº¦æ”¹å–„
        avg_complexity = analysis["complexity_analysis"].get("average_complexity", 0)
        if avg_complexity > 8:
            improvements.append(
                {
                    "type": "complexity_reduction",
                    "current_complexity": avg_complexity,
                    "target_complexity": 6,
                    "priority": "medium",
                    "estimated_effort": "high",
                }
            )

        return improvements

    async def apply_improvement(self, improvement: dict[str, Any]) -> dict[str, Any]:
        """æ”¹å–„é©ç”¨"""
        improvement_type = improvement["type"]

        if improvement_type == "test_coverage_improvement":
            return await self._improve_test_coverage(improvement)
        elif improvement_type == "type_annotation_addition":
            return await self._add_type_annotations(improvement)
        elif improvement_type == "docstring_addition":
            return await self._add_docstrings(improvement)
        elif improvement_type == "complexity_reduction":
            return await self._reduce_complexity(improvement)
        else:
            return {
                "success": False,
                "error": f"Unknown improvement type: {improvement_type}",
            }

    async def _improve_test_coverage(
        self, improvement: dict[str, Any]
    ) -> dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„"""
        # å®Ÿè£…ä¾‹: ä¸è¶³ã—ã¦ã„ã‚‹ãƒ†ã‚¹ãƒˆã‚’ç‰¹å®šã—ã€åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ
        try:
            # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰æœªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
            uncovered_files = await self._find_uncovered_files()

            tests_generated = 0
            for file_path in uncovered_files[:3]:  # æœ€åˆã®3ãƒ•ã‚¡ã‚¤ãƒ«
                test_content = await self._generate_basic_test(file_path)
                if test_content:
                    test_file = self._get_test_file_path(file_path)
                    if not test_file.exists():
                        test_file.parent.mkdir(parents=True, exist_ok=True)
                        with open(test_file, "w", encoding="utf-8") as f:
                            f.write(test_content)
                        tests_generated += 1

            return {
                "success": True,
                "tests_generated": tests_generated,
                "improvement": f"Generated {tests_generated} test files",
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _add_type_annotations(
        self, improvement: dict[str, Any]
    ) -> dict[str, Any]:
        """å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ """
        try:
            # mypyã‚’ä½¿ç”¨ã—ã¦å‹ã‚¨ãƒ©ãƒ¼ã‚’ç‰¹å®š
            subprocess.run(
                ["python", "-m", "mypy", ".", "--ignore-missing-imports"],
                capture_output=True,
                text=True,
                timeout=60,
            )

            annotations_added = 0

            # ç°¡å˜ãªå‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ ï¼ˆåŸºæœ¬å‹ã®ã¿ï¼‰
            for file_path in Path(".").rglob("*.py"):
                if await self._add_basic_type_annotations(file_path):
                    annotations_added += 1

            return {
                "success": True,
                "annotations_added": annotations_added,
                "improvement": f"Added type annotations to {annotations_added} files",
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _add_docstrings(self, improvement: dict[str, Any]) -> dict[str, Any]:
        """docstringè¿½åŠ """
        try:
            docstrings_added = 0

            for file_path in Path(".").rglob("*.py"):
                if await self._add_basic_docstrings(file_path):
                    docstrings_added += 1

            return {
                "success": True,
                "docstrings_added": docstrings_added,
                "improvement": f"Added docstrings to {docstrings_added} files",
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _reduce_complexity(self, improvement: dict[str, Any]) -> dict[str, Any]:
        """è¤‡é›‘åº¦å‰Šæ¸›"""
        # å®Ÿè£…ä¾‹: è¤‡é›‘ãªé–¢æ•°ã‚’ç‰¹å®šã—ã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆã‚’ç”Ÿæˆ
        try:
            complex_functions = await self._find_complex_functions()

            refactoring_suggestions = []
            for func_info in complex_functions[:5]:  # æœ€åˆã®5ã¤
                suggestion = await self._generate_refactoring_suggestion(func_info)
                refactoring_suggestions.append(suggestion)

            return {
                "success": True,
                "suggestions_generated": len(refactoring_suggestions),
                "improvement": f"Generated {len(refactoring_suggestions)} refactoring suggestions",
                "suggestions": refactoring_suggestions,
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _find_uncovered_files(self) -> list[Path]:
        """æœªã‚«ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š"""
        # ç°¡æ˜“å®Ÿè£…: Python ãƒ•ã‚¡ã‚¤ãƒ«ã®ã†ã¡ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„ã‚‚ã®ã‚’è¿”ã™
        all_python_files = list(Path(".").rglob("*.py"))
        return [
            f
            for f in all_python_files[:5]
            if "test" not in f.name.lower()
            and "__pycache__" not in str(f)
            and not str(f).startswith(".")
        ]

    async def _generate_basic_test(self, file_path: Path) -> str | None:
        """åŸºæœ¬ãƒ†ã‚¹ãƒˆç”Ÿæˆ"""
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
                tree = ast.parse(content)

            functions = []
            classes = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and not node.name.startswith("_"):
                    functions.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)

            if not functions and not classes:
                return None

            # åŸºæœ¬ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
            module_name = file_path.stem
            import_path = str(file_path.with_suffix("")).replace("/", ".")

            test_content = f'''"""
Test module for {module_name}

Auto-generated basic tests for coverage improvement.
"""

import pytest
from {import_path} import {", ".join(functions + classes)}


'''

            # é–¢æ•°ãƒ†ã‚¹ãƒˆç”Ÿæˆ
            for func_name in functions:
                test_content += f'''def test_{func_name}():
    """Test {func_name} function"""
    # TODO: Implement actual test logic
    assert True  # Placeholder test


'''

            # ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆç”Ÿæˆ
            for class_name in classes:
                test_content += f'''class Test{class_name}:
    """Test {class_name} class"""

    def test_init(self):
        """Test {class_name} initialization"""
        # TODO: Implement actual test logic
        assert True  # Placeholder test


'''

            return test_content

        except Exception:
            return None

    def _get_test_file_path(self, source_file: Path) -> Path:
        """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—"""
        test_dir = Path("tests")
        relative_path = source_file.relative_to(Path("."))
        test_file_name = f"test_{relative_path.stem}.py"
        return test_dir / relative_path.parent / test_file_name

    async def _add_basic_type_annotations(self, file_path: Path) -> bool:
        """åŸºæœ¬å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ """
        # å®Ÿè£…çœç•¥: å®Ÿéš›ã«ã¯ AST ã‚’ä½¿ã£ã¦å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        return False

    async def _add_basic_docstrings(self, file_path: Path) -> bool:
        """åŸºæœ¬docstringè¿½åŠ """
        # å®Ÿè£…çœç•¥: å®Ÿéš›ã«ã¯ AST ã‚’ä½¿ã£ã¦ docstring ã‚’è¿½åŠ 
        return False

    async def _find_complex_functions(self) -> list[dict[str, Any]]:
        """è¤‡é›‘ãªé–¢æ•°ç‰¹å®š"""
        return []

    async def _generate_refactoring_suggestion(
        self, func_info: dict[str, Any]
    ) -> dict[str, Any]:
        """ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆç”Ÿæˆ"""
        return {"suggestion": "Extract method"}


class AutonomousRefactoringAgent(AutonomousAgent):
    """è‡ªå¾‹çš„ã‚³ãƒ¼ãƒ‰ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self):
        super().__init__(
            agent_id="refactoring_agent",
            specialization="code_quality_improvement",
            config={
                "cycle_interval": 120,  # 2åˆ†é–“éš”
                "quality_threshold": 80,
                "max_improvements_per_cycle": 3,
            },
        )

        self.analyzer = CodeQualityAnalyzer()
        self.refactoring_engine = CodeRefactoringEngine()
        self.baseline_analysis = None

    async def _get_project_status(self) -> dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³å–å¾—"""
        python_files = list(Path(".").rglob("*.py"))
        return {
            "total_python_files": len(python_files),
            "project_type": "python_project",
            "status": "active",
        }

    async def _get_quality_metrics(self) -> dict[str, Any]:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        return await self.analyzer.analyze_codebase()

    async def _get_specialized_actions(
        self, analysis: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å°‚ç”¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        actions = []

        quality_metrics = analysis.get("quality_metrics", {})
        overall_score = quality_metrics.get("overall_score", 0)

        # å“è³ªã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹å ´åˆã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        if overall_score < self.config["quality_threshold"]:
            # æ”¹å–„ææ¡ˆç”Ÿæˆ
            improvements = await self.refactoring_engine.generate_improvements(
                quality_metrics
            )

            # æœ€å¤§æ”¹å–„æ•°ã¾ã§é¸æŠ
            selected_improvements = improvements[
                : self.config["max_improvements_per_cycle"]
            ]

            for improvement in selected_improvements:
                actions.append(
                    {
                        "type": "apply_refactoring",
                        "improvement": improvement,
                        "priority": improvement.get("priority", "medium"),
                    }
                )

        return actions

    async def _execute_specialized_action(
        self, action: dict[str, Any]
    ) -> dict[str, Any]:
        """ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        if action["type"] == "apply_refactoring":
            improvement = action["improvement"]
            result = await self.refactoring_engine.apply_improvement(improvement)

            if result.get("success", False):
                self.performance_metrics["quality_improvements"] += 1

            return result

        return {"success": False, "error": "Unknown action type"}

    async def _initialize_agent(self) -> None:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        await super()._initialize_agent()

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œ
        self.baseline_analysis = await self.analyzer.analyze_codebase()

        self.logger.info("Refactoring agent initialized with baseline analysis")
        self.logger.info(
            f"Baseline quality score: {self.baseline_analysis.get('overall_score', 0)}"
        )


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”„ Starting Autonomous Code Refactoring Agent...")

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agent = AutonomousRefactoringAgent()

    try:
        # åˆæœŸåˆ†æå®Ÿè¡Œ
        print("ğŸ“Š Running initial code analysis...")
        initial_analysis = await agent.analyzer.analyze_codebase()
        print(f"Initial quality score: {initial_analysis.get('overall_score', 0)}")

        # çŸ­æœŸé–“ã®è‡ªå¾‹å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
        print("ğŸ¤– Starting autonomous refactoring cycle...")

        # éåŒæœŸã§å®Ÿè¡Œé–‹å§‹
        asyncio.create_task(agent.start_autonomous_cycle())

        # 5åˆ†é–“å®Ÿè¡Œ
        await asyncio.sleep(300)

        # åœæ­¢
        await agent.stop_autonomous_cycle()

        # æœ€çµ‚çµæœ
        final_report = agent.get_performance_report()
        print("\nğŸ“Š Final Performance Report:")
        print(json.dumps(final_report, indent=2, ensure_ascii=False))

        # æ”¹å–„çµæœåˆ†æ
        final_analysis = await agent.analyzer.analyze_codebase()
        print(
            f"\nQuality improvement: {initial_analysis.get('overall_score', 0)} â†’ {final_analysis.get('overall_score', 0)}"
        )

    except KeyboardInterrupt:
        print("\nâ¹ï¸ Refactoring agent stopped by user")
        await agent.stop_autonomous_cycle()
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        await agent.stop_autonomous_cycle()


if __name__ == "__main__":
    asyncio.run(main())
